; NOTE: Assertions have been autogenerated by test/update_tpde_llc_test_checks.py UTC_ARGS: --version 5
; SPDX-FileCopyrightText: 2025 Contributors to TPDE <https://tpde.org>
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

; RUN: tpde-llc --target=x86_64 %s | %objdump | FileCheck %s -check-prefixes=X64
; RUN: tpde-llc --target=aarch64 %s | %objdump | FileCheck %s -check-prefixes=ARM64

define i8 @ext_v5i8_0(ptr %p) {
; X64-LABEL: <ext_v5i8_0>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    push rbx
; X64-NEXT:    nop dword ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x28
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rdi + 0x1]
; X64-NEXT:    movzx edx, byte ptr [rdi + 0x2]
; X64-NEXT:    movzx ebx, byte ptr [rdi + 0x3]
; X64-NEXT:    movzx esi, byte ptr [rdi + 0x4]
; X64-NEXT:    add rsp, 0x28
; X64-NEXT:    pop rbx
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v5i8_0>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldrb w1, [x0]
; ARM64-NEXT:    ldrb w2, [x0, #0x1]
; ARM64-NEXT:    ldrb w3, [x0, #0x2]
; ARM64-NEXT:    ldrb w4, [x0, #0x3]
; ARM64-NEXT:    ldrb w5, [x0, #0x4]
; ARM64-NEXT:    mov w0, w1
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %v = load <5 x i8>, ptr %p
  %r = extractelement <5 x i8> %v, i32 0
  ret i8 %r
}

define i8 @ext_v5i8_3(ptr %p) {
; X64-LABEL: <ext_v5i8_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    push rbx
; X64-NEXT:    nop dword ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x28
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rdi + 0x1]
; X64-NEXT:    movzx edx, byte ptr [rdi + 0x2]
; X64-NEXT:    movzx ebx, byte ptr [rdi + 0x3]
; X64-NEXT:    movzx esi, byte ptr [rdi + 0x4]
; X64-NEXT:    mov eax, ebx
; X64-NEXT:    add rsp, 0x28
; X64-NEXT:    pop rbx
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v5i8_3>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldrb w1, [x0]
; ARM64-NEXT:    ldrb w2, [x0, #0x1]
; ARM64-NEXT:    ldrb w3, [x0, #0x2]
; ARM64-NEXT:    ldrb w4, [x0, #0x3]
; ARM64-NEXT:    ldrb w5, [x0, #0x4]
; ARM64-NEXT:    mov w0, w4
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %v = load <5 x i8>, ptr %p
  %r = extractelement <5 x i8> %v, i32 3
  ret i8 %r
}

define i8 @ext_v5i8_3_twice(ptr %p) {
; X64-LABEL: <ext_v5i8_3_twice>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    push rbx
; X64-NEXT:    nop dword ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x28
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rdi + 0x1]
; X64-NEXT:    movzx edx, byte ptr [rdi + 0x2]
; X64-NEXT:    movzx ebx, byte ptr [rdi + 0x3]
; X64-NEXT:    movzx esi, byte ptr [rdi + 0x4]
; X64-NEXT:    mov edi, ebx
; X64-NEXT:    lea edi, [rdi + rbx]
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x28
; X64-NEXT:    pop rbx
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v5i8_3_twice>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldrb w1, [x0]
; ARM64-NEXT:    ldrb w2, [x0, #0x1]
; ARM64-NEXT:    ldrb w3, [x0, #0x2]
; ARM64-NEXT:    ldrb w4, [x0, #0x3]
; ARM64-NEXT:    ldrb w5, [x0, #0x4]
; ARM64-NEXT:    mov w0, w4
; ARM64-NEXT:    add w4, w4, w0
; ARM64-NEXT:    mov w0, w4
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %v = load <5 x i8>, ptr %p
  %r1 = extractelement <5 x i8> %v, i32 3
  %r2 = extractelement <5 x i8> %v, i32 3
  %r = add i8 %r1, %r2
  ret i8 %r
}

define i8 @ext_v5i8_dyn(ptr %p, i32 %i) {
; X64-LABEL: <ext_v5i8_dyn>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    push rbx
; X64-NEXT:    nop dword ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x28
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rdi + 0x1]
; X64-NEXT:    movzx edx, byte ptr [rdi + 0x2]
; X64-NEXT:    movzx ebx, byte ptr [rdi + 0x3]
; X64-NEXT:    movzx r8d, byte ptr [rdi + 0x4]
; X64-NEXT:    mov byte ptr [rbp - 0x30], al
; X64-NEXT:    mov byte ptr [rbp - 0x2f], cl
; X64-NEXT:    mov byte ptr [rbp - 0x2e], dl
; X64-NEXT:    mov byte ptr [rbp - 0x2d], bl
; X64-NEXT:    mov byte ptr [rbp - 0x2c], r8b
; X64-NEXT:    xor edx, edx
; X64-NEXT:    mov rdi, 0x5
; X64-NEXT:    mov rax, rsi
; X64-NEXT:    div rdi
; X64-NEXT:    movzx eax, byte ptr [rbp + rdx - 0x30]
; X64-NEXT:    add rsp, 0x28
; X64-NEXT:    pop rbx
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v5i8_dyn>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldrb w2, [x0]
; ARM64-NEXT:    ldrb w3, [x0, #0x1]
; ARM64-NEXT:    ldrb w4, [x0, #0x2]
; ARM64-NEXT:    ldrb w5, [x0, #0x3]
; ARM64-NEXT:    ldrb w6, [x0, #0x4]
; ARM64-NEXT:    strb w2, [x29, #0xa0]
; ARM64-NEXT:    strb w3, [x29, #0xa1]
; ARM64-NEXT:    strb w4, [x29, #0xa2]
; ARM64-NEXT:    strb w5, [x29, #0xa3]
; ARM64-NEXT:    strb w6, [x29, #0xa4]
; ARM64-NEXT:    mov x0, #0x5 // =5
; ARM64-NEXT:    udiv x7, x1, x0
; ARM64-NEXT:    msub x0, x7, x0, x1
; ARM64-NEXT:    add x0, x29, x0
; ARM64-NEXT:    ldrb w1, [x0, #0xa0]
; ARM64-NEXT:    mov w0, w1
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %v = load <5 x i8>, ptr %p
  %r = extractelement <5 x i8> %v, i32 %i
  ret i8 %r
}

define i8 @ext_v16i8_0(<16 x i8> %v) {
; X64-LABEL: <ext_v16i8_0>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    movzx eax, byte ptr [rbp - 0x40]
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v16i8_0>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    umov w0, v0.b[0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = extractelement <16 x i8> %v, i32 0
  ret i8 %r
}

define i8 @ext_v16i8_11(<16 x i8> %v) {
; X64-LABEL: <ext_v16i8_11>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    movzx eax, byte ptr [rbp - 0x35]
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v16i8_11>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    umov w0, v0.b[11]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = extractelement <16 x i8> %v, i32 11
  ret i8 %r
}

define i8 @ext_v16i8_dyn(<16 x i8> %v, i32 %i) {
; X64-LABEL: <ext_v16i8_dyn>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    and rdi, 0xf
; X64-NEXT:    movzx eax, byte ptr [rbp + rdi - 0x40]
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v16i8_dyn>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    str q0, [x29, #0xa0]
; ARM64-NEXT:    and x0, x0, #0xf
; ARM64-NEXT:    add x0, x29, x0
; ARM64-NEXT:    ldrb w1, [x0, #0xa0]
; ARM64-NEXT:    mov w0, w1
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %r = extractelement <16 x i8> %v, i32 %i
  ret i8 %r
}

define i8 @ext_v64i8_0(ptr %p) {
; X64-LABEL: <ext_v64i8_0>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x70
; X64-NEXT:    movaps xmm0, xmmword ptr [rdi]
; X64-NEXT:    movaps xmm1, xmmword ptr [rdi + 0x10]
; X64-NEXT:    movaps xmm2, xmmword ptr [rdi + 0x20]
; X64-NEXT:    movaps xmm3, xmmword ptr [rdi + 0x30]
; X64-NEXT:    movapd xmmword ptr [rbp - 0x70], xmm0
; X64-NEXT:    movzx eax, byte ptr [rbp - 0x70]
; X64-NEXT:    add rsp, 0x70
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v64i8_0>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldr q0, [x0]
; ARM64-NEXT:    ldr q1, [x0, #0x10]
; ARM64-NEXT:    ldr q2, [x0, #0x20]
; ARM64-NEXT:    ldr q3, [x0, #0x30]
; ARM64-NEXT:    umov w0, v0.b[0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %v = load <64 x i8>, ptr %p
  %r = extractelement <64 x i8> %v, i32 0
  ret i8 %r
}

define i8 @ext_v64i8_43(ptr %p) {
; X64-LABEL: <ext_v64i8_43>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x70
; X64-NEXT:    movaps xmm0, xmmword ptr [rdi]
; X64-NEXT:    movaps xmm1, xmmword ptr [rdi + 0x10]
; X64-NEXT:    movaps xmm2, xmmword ptr [rdi + 0x20]
; X64-NEXT:    movaps xmm3, xmmword ptr [rdi + 0x30]
; X64-NEXT:    movapd xmmword ptr [rbp - 0x50], xmm2
; X64-NEXT:    movzx eax, byte ptr [rbp - 0x45]
; X64-NEXT:    add rsp, 0x70
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v64i8_43>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldr q0, [x0]
; ARM64-NEXT:    ldr q1, [x0, #0x10]
; ARM64-NEXT:    ldr q2, [x0, #0x20]
; ARM64-NEXT:    ldr q3, [x0, #0x30]
; ARM64-NEXT:    umov w0, v2.b[11]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %v = load <64 x i8>, ptr %p
  %r = extractelement <64 x i8> %v, i32 43
  ret i8 %r
}

define i8 @ext_v64i8_43_twice(ptr %p) {
; X64-LABEL: <ext_v64i8_43_twice>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x70
; X64-NEXT:    movaps xmm0, xmmword ptr [rdi]
; X64-NEXT:    movaps xmm1, xmmword ptr [rdi + 0x10]
; X64-NEXT:    movaps xmm2, xmmword ptr [rdi + 0x20]
; X64-NEXT:    movaps xmm3, xmmword ptr [rdi + 0x30]
; X64-NEXT:    movapd xmmword ptr [rbp - 0x50], xmm2
; X64-NEXT:    movzx eax, byte ptr [rbp - 0x45]
; X64-NEXT:    movzx ecx, byte ptr [rbp - 0x45]
; X64-NEXT:    lea eax, [rax + rcx]
; X64-NEXT:    add rsp, 0x70
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v64i8_43_twice>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldr q0, [x0]
; ARM64-NEXT:    ldr q1, [x0, #0x10]
; ARM64-NEXT:    ldr q2, [x0, #0x20]
; ARM64-NEXT:    ldr q3, [x0, #0x30]
; ARM64-NEXT:    umov w0, v2.b[11]
; ARM64-NEXT:    umov w1, v2.b[11]
; ARM64-NEXT:    add w1, w1, w0
; ARM64-NEXT:    mov w0, w1
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %v = load <64 x i8>, ptr %p
  %r1 = extractelement <64 x i8> %v, i32 43
  %r2 = extractelement <64 x i8> %v, i32 43
  %r = add i8 %r1, %r2
  ret i8 %r
}

define i8 @ext_v64i8_dyn(ptr %p, i32 %i) {
; X64-LABEL: <ext_v64i8_dyn>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x70
; X64-NEXT:    movaps xmm0, xmmword ptr [rdi]
; X64-NEXT:    movaps xmm1, xmmword ptr [rdi + 0x10]
; X64-NEXT:    movaps xmm2, xmmword ptr [rdi + 0x20]
; X64-NEXT:    movaps xmm3, xmmword ptr [rdi + 0x30]
; X64-NEXT:    movapd xmmword ptr [rbp - 0x70], xmm0
; X64-NEXT:    movapd xmmword ptr [rbp - 0x60], xmm1
; X64-NEXT:    movapd xmmword ptr [rbp - 0x50], xmm2
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm3
; X64-NEXT:    and rsi, 0x3f
; X64-NEXT:    movzx eax, byte ptr [rbp + rsi - 0x70]
; X64-NEXT:    add rsp, 0x70
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v64i8_dyn>:
; ARM64:         sub sp, sp, #0xe0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldr q0, [x0]
; ARM64-NEXT:    ldr q1, [x0, #0x10]
; ARM64-NEXT:    ldr q2, [x0, #0x20]
; ARM64-NEXT:    ldr q3, [x0, #0x30]
; ARM64-NEXT:    str q0, [x29, #0xa0]
; ARM64-NEXT:    str q1, [x29, #0xb0]
; ARM64-NEXT:    str q2, [x29, #0xc0]
; ARM64-NEXT:    str q3, [x29, #0xd0]
; ARM64-NEXT:    and x1, x1, #0x3f
; ARM64-NEXT:    add x1, x29, x1
; ARM64-NEXT:    ldrb w0, [x1, #0xa0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xe0
; ARM64-NEXT:    ret
  %v = load <64 x i8>, ptr %p
  %r = extractelement <64 x i8> %v, i32 %i
  ret i8 %r
}

define i32 @ext_v4i32_0(<4 x i32> %v) {
; X64-LABEL: <ext_v4i32_0>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    mov eax, dword ptr [rbp - 0x40]
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v4i32_0>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    mov w0, v0.s[0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = extractelement <4 x i32> %v, i32 0
  ret i32 %r
}

define i32 @ext_v4i32_3(<4 x i32> %v) {
; X64-LABEL: <ext_v4i32_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    mov eax, dword ptr [rbp - 0x34]
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v4i32_3>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    mov w0, v0.s[3]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = extractelement <4 x i32> %v, i32 3
  ret i32 %r
}

define i32 @ext_v4i32_dyn(<4 x i32> %v, i32 %i) {
; X64-LABEL: <ext_v4i32_dyn>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    and rdi, 0x3
; X64-NEXT:    mov eax, dword ptr [rbp + 4*rdi - 0x40]
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v4i32_dyn>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    str q0, [x29, #0xa0]
; ARM64-NEXT:    and x0, x0, #0x3
; ARM64-NEXT:    add x0, x29, x0, lsl #2
; ARM64-NEXT:    ldr w1, [x0, #0xa0]
; ARM64-NEXT:    mov w0, w1
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %r = extractelement <4 x i32> %v, i32 %i
  ret i32 %r
}

define double @ext_v2f64_0(<2 x double> %v) {
; X64-LABEL: <ext_v2f64_0>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    movsd xmm1, qword ptr [rbp - 0x40]
; X64-NEXT:    movapd xmm0, xmm1
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v2f64_0>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    mov d1, v0.d[0]
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = extractelement <2 x double> %v, i32 0
  ret double %r
}

define double @ext_v2f64_1(<2 x double> %v) {
; X64-LABEL: <ext_v2f64_1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    movsd xmm1, qword ptr [rbp - 0x38]
; X64-NEXT:    movapd xmm0, xmm1
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v2f64_1>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    mov d1, v0.d[1]
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = extractelement <2 x double> %v, i32 1
  ret double %r
}

define double @ext_v2f64_dyn(<2 x double> %v, i32 %i) {
; X64-LABEL: <ext_v2f64_dyn>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movapd xmmword ptr [rbp - 0x40], xmm0
; X64-NEXT:    and rdi, 0x1
; X64-NEXT:    movsd xmm1, qword ptr [rbp + 8*rdi - 0x40]
; X64-NEXT:    movapd xmm0, xmm1
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ext_v2f64_dyn>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    str q0, [x29, #0xa0]
; ARM64-NEXT:    and x0, x0, #0x1
; ARM64-NEXT:    add x0, x29, x0, lsl #3
; ARM64-NEXT:    ldr d1, [x0, #0xa0]
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %r = extractelement <2 x double> %v, i32 %i
  ret double %r
}
